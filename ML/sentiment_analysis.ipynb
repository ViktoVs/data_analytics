{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11a8b086-88a9-4984-97a0-197bd3795420",
   "metadata": {},
   "source": [
    "<h1> To-Do </h1>\n",
    "\n",
    "* Cleaning & Description\n",
    "* add other models\n",
    "* try to perform model operations in numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cf8f7d-7527-4783-b54a-15b75f6006e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/home/viktov/Documents/programming_test_data/Reviews.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c69ab4-787b-4b3f-a12f-494d2038c9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append('/home/viktov/Documents/repositories/data_analytics')\n",
    "\n",
    "from viktors_little_helpers.visualization_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e28210-8c3f-493c-97df-cf52c8220d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def df_histogram(df, column):\n",
    "    \"\"\"\n",
    "    Create a Histogram with a KDE curve\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(16,10))\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\")\n",
    "    display(sns.histplot(df[column], discrete=True))\n",
    "    \n",
    "df_histogram(df, 'Score')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259a56a6-a4fa-4bb9-bfb4-34bc960ec9e6",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/a-beginners-guide-to-sentiment-analysis-in-python-95e354ea84f6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a033b5-467d-4fc1-a608-9d3d1868355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords# Create stopword list:\n",
    "stopwords = set(STOPWORDS)\n",
    "stopwords.update([\"br\", \"href\"])\n",
    "textt = \" \".join(review for review in df.Text)\n",
    "wordcloud = WordCloud(stopwords=stopwords).generate(textt)plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.savefig('wordcloud11.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afce033-4a9f-4f46-85da-95eec7fa6a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Create stopword list:\n",
    "nltk.download('stopwords')\n",
    "stops = set(stopwords.words('english'))\n",
    "stops.update([\"br\", \"href\"])\n",
    "\n",
    "# build basis text for wordcloud\n",
    "textt = \" \".join(review for review in df.Text)\n",
    "wordcloud = WordCloud(stopwords=stops).generate(textt)\n",
    "\n",
    "# display Wordcloud\n",
    "fig = plt.figure(figsize=(16,10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.savefig('amz_product_reviews.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b78d3d2-6163-4078-9f90-a061b279f676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign reviews with score > 3 as positive sentiment\n",
    "# score < 3 negative sentiment\n",
    "# remove score = 3df = df[df['Score'] != 3]\n",
    "df[\"Sentiment\"] = df[\"Score\"].apply(lambda score : +1 if score > 3 else 0 if score == 3 else -1)\n",
    "\n",
    "pos_df = df[df[\"Sentiment\"] == 1]\n",
    "neg_df = df[df[\"Sentiment\"] == -1]\n",
    "\n",
    "neg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce1e72c-d94d-4e6e-9d20-11a9b064c862",
   "metadata": {},
   "outputs": [],
   "source": [
    "loop_dict = {\n",
    "    \"positive\": pos_df\n",
    "    , \"negative\": neg_df\n",
    "}\n",
    "\n",
    "\n",
    "stops = set(stopwords.words(\"english\"))\n",
    "stops.update([\"br\", \"href\"])\n",
    "# stops.update([\"br\", \"href\", \"good\", \"great\"]) ### not good and not great are often used in negative senteces \n",
    "\n",
    "\n",
    "for pn, df in loop_dict.items():\n",
    "    # Create stopword list:\n",
    "\n",
    "    # build basis text for wordcloud\n",
    "    textt = \" \".join(review for review in df.Text)\n",
    "    wordcloud = WordCloud(stopwords=stops).generate(textt)\n",
    "\n",
    "    # display Wordcloud\n",
    "    fig = plt.figure(figsize=(16,10))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"{pn}_amz_product_reviews.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd7cec3-e3b9-4bbe-8a2a-5e947c231639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    final = \"\".join(u for u in str(text) if u not in (\"\"\"?.;:!\"'\"\"\"))\n",
    "    return final\n",
    "\n",
    "df = df.dropna(subset=['Summary'])\n",
    "\n",
    "df[\"Text\"] = df[\"Text\"].apply(remove_punctuation)\n",
    "df[\"Summary\"] = df[\"Summary\"].apply(remove_punctuation)\n",
    "\n",
    "df_new = df[[\"Summary\",\"Sentiment\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcdea9a-304e-40ca-a7df-38cf86d7fb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[\"Summary\"]\n",
    "y = df[\"Sentiment\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X\n",
    "                                                    , y\n",
    "                                                    , test_size=0.25\n",
    "                                                    , random_state=42)\n",
    "\n",
    "# count vectorizer:\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "#y_train = vectorizer.fit_transform(y_train)\n",
    "#y_test = vectorizer.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9492c6-6030-433b-80d4-4a2795ec832d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5049b03c-a02e-4d9c-9662-623d7d8d33b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a351cf97-75f9-4f8e-a90c-41a98af0cde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "new = np.asarray(y_test)\n",
    "sum(confusion_matrix(predictions,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba91fb28-a8ba-4863-809b-28a85b682e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(predictions,y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
